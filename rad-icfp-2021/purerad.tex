\section{Simple pure reverse-mode differentiation}
\label{sec:simplediff}

\subsection{Source Language}
\label{sub:sourcelang}

We consider a standard call-by-value language. 
It consists of a first-order functional language with arrays and a few typical second-order array operations. 
The types !T1,T2! and terms !e1,e2! are given in Figure~\ref{fig:source_grammar}.
We have included a minimal set of array operations for the sake of illustration,  it is not hard to add more.
See Section~\ref{sec:generalization}.

\input{figures/source_grammar}

The typing rules are given in Figure~\ref{fig:source_typesystem}. 
For scalar operations, we assume a given set of operations, including $+$ and $*$. 
!op1! and !op2! denote respectively a unary and a binary operation on reals. 
These operations represent smooth total functions, 
but again this can be easily generalized (\S\ref{sec:generalization}).  
Typical examples include !cos, exp, +, *!. 
We use infix notation for binary operators.

The !reduce! operator is a fold-left operator for which the function is assumed to be associative, 
and the provided initial value should be a unit of the binary operation.
It is a well-known parallel friendly construct. 
For the sake of simplicity in the presentation, the bound function in !reduce! 
is restricted to having no free variables. Furthermore, as our main focus is on AD and not array processing,
we currently restrict to arrays of reals.
We show how to lift these restrictions and how to differentiate some other array operators in Section~\ref{sec:generalization}.

\input{figures/source_type_system}

\subsection{Target Language}

The target language of our source-code transformation is an extension to the source language.
It is a higher-order language, as our purely functional reverse-mode introduces a continuation.
The set of scalar operations should also be closed under partial differentiation. 
In more detail, for every unary scalar operation !op1!, 
we assumed a given operator $\partial$!op1! whose semantics should be the derivative of !op1!, e.g. $\partial$!cos!=!sin!.
Similarly, for every binary operator !op2!, we assume given operators $\partial_1$!op2!, $\partial_2$!op2!, 
respectively representing the first and second partial derivative of !op2!.

Similarly, the target language contains more array primitives which are used to define the reverse derivatives of array operations. 
Scan left !scanl! is similar to fold left but also stores all the intermediate results in an array, which it returns.
In the same vein, scan right !scanr! performs a fold left by reading the array from right to left and stores 
the intermediate results in an array from right to left.

Finally, we add two new shift operators !shift1L! and !shift1R!. 
They take an array of size $n$, and respectively forget the first and the last element of the array.
These somewhat ad-hoc operators naturally show up when differentiating fold-like operators.

The types and terms are presented in Figure~\ref{fig:target_grammar}.
Our lambda abstractions take $n$ arguments as we are not interested here with partial applications. 
In fact, the lambda abstractions introduced by reverse-mode will be removed during partial evaluation, 
and the notation with lambda abstractions having $n$ bound variables makes reading slightly easier.
We note that we don't actually need the full power of higher-order because we only use lambda abstractions over variables of ground types
and let expressions binding such lambda abstractions. We only need the target language to be second-order.
The type system for the extended grammar of the target language is presented in Figure~\ref{fig:target_typesystem}. 

\input{figures/target_grammar}

\input{figures/target_type_system}

\subsection{Macro for pure reverse mode transformation} % (fold)
\label{sub:Macro for pure reverse mode transformation}

In Figure~\ref{fig:direct_diff_macro} we present our direct transformation from the source language to the target language for pure reverse mode differentiation.
Given a term $\Gamma\vdash e : \reals$, we can compute its gradient $\grad_\Gamma e$ from a particular instance of 
$\directD{\rho}{\Gamma}{Y}(e)$. First, $\rho, Y$ specifies if we want to compute the whole gradient regarding the variables from $\Gamma$ or a subset of it.
For a subset $\rho\subset \Gamma$, one chooses $Y$ to be the projection function sending a variable 
$x_i:G$ of $\Gamma$ to $x_i$ if it belongs to $\rho$ and to $0_G$ otherwise.
In particular, we take $Y=Id_\Gamma$ to compute the whole gradient.
Next, the gradient will be given by the second part of the pair $\directD{\rho}{\Gamma}{Y}(e)$, 
and we need to initialize the tangent variables. All of them are set to $0$ except the one corresponding to the output value of !e!, 
which we initialize at $1$ to run the backpropagation. 
All in all, we compute the gradient via $\pi_2\directD{\rho}{\Gamma}{Id_\Gamma}(e)(0_\Gamma,1)$.

\input{figures/notation}

\begin{notation}
We now introduce several notations which are useful when defining the transformation for reverse-mode in Figure~\ref{tbl:notation:one}.
Ground types are defined inductively by 
$$G::= \RR \mid G\times \ldots \times G \mid \Array{\RR}{n}$$

$(\RR,+,\underline{0})$ forms a monoid and this monoid structure extends canonically 
to a monoid structure $(G,\widehat{+},0_G)$ for every ground type $G$. 
It is defined inductively on $G$ as follows

\begin{tabular}{l c l}
    $0_\RR$  & $\defeq$ & $\underline{0}$ \\
    $0_{G_1\times \ldots \times G_n}$ & $\defeq$ &  $< O_{G_1},\ldots, 0_{G_n} >$ \\
    $0_{\Array{\RR}{n}}$& $\defeq$ & !ZerosLike(n)! \\
    $a\widehat{+}_\RR b$ & $\defeq$ & $ a+b$ \\
    $(a_1,\ldots,a_n)\widehat{+}_{G_1\times\ldots\times G_n}(b_1,\ldots,b_n)$ & $\defeq$ & $(a_1\widehat{+}_{G_1}b_1,\ldots,a_n\widehat{+}_{G_n}b_n)$ \\
    $A\widehat{+}_{\Array{\RR}{n}}B $ & $\defeq$ & !map2! + $A$ $B$ 
\end{tabular}

A ground context is a context only containing variables of ground type.
The previous monoid structure again extends canonically on ground contexts $\Gamma$ by defining
$0_{x1:G1,\ldots,x_n:G_n}\defeq 0_{G_1},\ldots,0_{G_n}$ and 
$a_1,\ldots,a_n\widehat{+}_{x1:G_1,\ldots, x_n:G_n}b_1,\ldots,b_n\defeq a_1\widehat{+}_{G_1}b_1,\ldots,a_n\widehat{+}_{G_n}b_n$.

\end{notation}

\begin{example}
    The reverse-mode transformation of the terms from the introduction are given by

    \begin{tabular}{c l}
        &$\directD{\rho}{\Gamma}{Y}$(!let w$_1$ = x$_1$ * x$_2$ in let w$_2$ = w$_1$ * x$_1$ in w$_2$!) \\
        =& !let w$_1$,Y$_1$=!\\
        & \quad\quad !let y$_{11}$,Y$_{11}$= <x$_1$, fun (y$_1$,y$_2$,y$_3$,z) -> Y(y$_1$+z,y$_2$,y$_3$)> in! \\
        & \quad\quad !let y$_{12}$,Y$_{12}$= <x$_{2}$, fun (y$_{1}$,y$_{2}$,y$_{3}$,y$_{4}$,z) -> Y$_{11}$(y$_{1}$,y$_{2}$+z,y$_{3}$,y$_{4}$)> in! \\
        & \quad\quad !<y$_{11}$ * y$_{12}$, fun (y$_{1}$,y$_{2}$,y$_{3}$,z) -> Y$_{12}$(y$_{1}$,y$_{2}$,y$_{3}$,y$_{12}$*z,y$_{11}$*z) > in! \\
        & !let w$_{2}$,Y$_{2}$=!\\
        & \quad\quad !let y$_{21}$,Y$_{21}$= <w$_{1}$, fun (y$_{1}$,y$_{2}$,y$_{3}$,y$_{4}$,z) -> Y$_1$(y$_{1}$,y$_{2}$,y$_{3}$,y$_{4}$+z)> in! \\
        & \quad\quad !let y$_{22}$,Y$_{22}$= <x$_{1}$, fun (y$_{1}$,y$_{2}$,y$_{3}$,y$_{4}$,y$_{5}$,z) -> Y$_{21}$(y$_{1}$+z,y$_{2}$,y$_{3}$,y$_{4}$,y$_{5}$)> in! \\
        & \quad\quad !<y$_{21}$ * y$_{22}$, fun (y$_{1}$,y$_{2}$,y$_{3}$,y$_{4}$,z) -> Y$_{22}$(y$_{1}$,y$_{2}$,y$_{3}$,y$_{4}$,y$_{22}$*z,y$_{21}$*z) > in! \\
        & !let y,Y$_{3}$= <w, fun (y$_{1}$,y$_{2}$,y$_{3}$,y$_{4}$,z) -> Y$_{2}$(y$_{1}$,y$_{2}$,y$_{3}$,y$_{4}$+z)> in! \\
        & !<y, fun (y$_{1}$,y$_{2}$,y$_{3}$,z) -> Y$_{3}$(y$_{1}$,y$_{2}$,y$_{3}$,0,z) >!
    \end{tabular}
    \medskip

    \begin{tabular}{c l}
        &$\directD{\rho}{\Gamma}{Y}$(!prod(A)!) \\
        =& !let y,Y$_{1}$= <1, fun (X,z) -> Y(X)> in! \\
        & !let B,Y$_{2}$= <A, fun (X,x,Z) -> Y$_{1}$(X+Z,x)> in!\\
        & !let A$_{0}$= shift1R (scanl * y B) in!\\
        & !let A$_{1}$= shift1L (map2 (a,b.b) A$_{0}$ B) in!\\
        & !let A$_{2}$= map2 (a,b.a) A$_{0}$ B in!\\
        & !let A$_{3}$= scanr * 1 A$_{1}$ in!\\
        & !<prod(B), fun (X,z) -> Y$_{2}$(X,0,map2 (a,b. a*z*b) A$_{2}$ A$_{3}$)>! 
    \end{tabular}
\end{example}

The idea is that $\rho$ represents the return type of the derivative part, which should be !A$_{1} \times \ldots \times$ A$_n$! 
if we want the whole gradient of a term !e! in context !$\Gamma = \;$x$_{1}$:A$_{1}$,$\ldots$,x$_n$:A$_n$!.
The subscript $\Gamma$ denotes the current context, 
which is locally augmented, for instance when differentiating a !let! rule.
For non-unary operations, we differentiate the arguments from the left to the right and add their derivatives to the current stack, 
which is modeled by the continuation $Y$. 
Importantly for performance, each continuation variable $Y$ is only used once.

We have the following typing lemma for $\directD{\rho}{\Gamma}{Y}$.
\begin{lemma}[Typing $\directD{\rho}{\Gamma}{Y}$]
    If $\Gamma \vdash$ !e: A!, then $\Gamma$!,Y:!$\Gamma\to \rho \vdash \directD{\rho}{\Gamma}{Y}$!(e): !$\directD{\rho}{\Gamma}{Y}$!(A)!.
\end{lemma}
\begin{proof}
By induction on derivation of $\Gamma\vdash$!e:A!.
\end{proof}

\input{figures/direct_macro_diff}

Admittedly, the transformation presented in this section may be hard to read, and it is not straightforward to show its correctness directly. 
Next, we decompose this transformation into three simpler steps via a novel intermediate representation.