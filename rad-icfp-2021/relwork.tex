\section{Conclusion}

\subsection{Summary} % (fold)
\label{sub:summary}

\subsection{Related Work} % (fold)
\label{sub:related_work}

\noindent \textbf{Automatic Differentiation.} 

\noindent \textbf{Array Languages and Fusion.}

\noindent \textbf{Numerical DSLs.} 

\noindent \textbf{Correctness of AD in functional languages.}

\noindent \textbf{Comparison to other recent papers.}

\subsection{Discussion and future work} % (fold)
\label{sub:discussion_and_future_work}

\noindent \textbf{Other Language features.}
%more primitives, proved correct and more efficient. extend library

\noindent \textbf{Probabilistic Programming.}
%find something simple and precise, o.w. useless section

\noindent \textbf{More dynamic language}
%TF is losing ground to Pytorch, Swift tries to renew with Pytorch-like dynamic features. 

\noindent \textbf{More optimisations.}
%maybe?

\noindent \textbf{Limitations.}
%maybe?

\MH{useful links (Swift is close to our project, and the doc is very readable):}

\begin{verbatim}https://docs.google.com/document/d/1_BirmTqdotglwNTOcYAW-ib6mx_jl-gH9Dbg4WmHZh0/edit# \end{verbatim}
\begin{verbatim}

	https://github.com/apple/swift/blob/master/docs/DifferentiableProgramming.md#approaches-to-automatic-differentiation
\end{verbatim}

\subsection{State-of-the-art} % (fold)
\label{sub:state_of_the_art}

All the existing work have either focused on efficiency or correctness.

We present \system{}, a correct and efficient functional differentiable programming framework. This is the first work that propose a pure reverse-mode AD on a higher-order functional language with a correctness proof and complexity guarantees that is implemented and achieves good practical performance. In Figure\ref{fig:comparison-table} we compare our work to the recent papers in the field. 

\MH{Separate complexity into complexity and performent.}
\MH{reorder topics: theory on the left, practice on the right, to make the dichotomy more apparent}
\MH{most refs here are pure, which is not good for our emphasis on pureness, need to add more practical papers}
\begin{table}
\label{fig:comparison-table}
\begin{tabular}{|l|c|c|c|c|c|c|c|c|c|c|}
\hline
 & Reverse  & Complexity & Impl. & Pure & Correct & HO Fun. & Tensors & Rec. & Cond. & HO $\partial$ ? \\
\hline
\system{} (This Paper) &
\supfull & \supfull & \supfull & \supfull & \supfull & \supfull  & \supfull  & \supfull & \supfull & \supfull \\ 
\hline
Lantern~\cite{lantern_icfp} & 
\supfull & \suphalf & \supfull & \supnone & \supnone & \supfull & \supfull & \supfull & \supfull &? \\ 
\hline
\dfsmooth{}~\cite{shaikhha2019efficient} 
& 
\supnone & \supnone & \supfull & \supfull & \supnone & \supfull & \supfull  & \supnone  & \supnone &? \\ 
\hline
\cite{huot2020correctness} &
\supfull & \supnone & \supnone & \supfull & \supfull & \supfull & \supnone & \suphalf & \supfull &?\\ 
\hline
\cite{brunel2019backpropagation} &
\supfull & \suphalf ? & \supnone & \supfull & \supfull & \supfull & \supnone & \supnone & \supnone &?\\ 
\hline
\cite{abadi2019simple} &
\supfull & \supfull? & \supnone & \supfull & \supfull & \supnone & \supnone? & \supfull & \supfull &?\\ 
\hline
\cite{barthe2020versatility} &
\supnone & \supnone & \supnone & \supfull & \supfull & \supnone? & \supnone & \supnone & \supfull &?\\ 
\hline
\cite{pearlmutter2008reverse} &
\supfull & \supfull (not proved) & \supfull & \supnone & \supnone(not proved) & \supfull & \supnone? & \supfull & \supfull &?\\ 
\hline
\cite{Elliott:2018:SEA:3243631.3236765} &
\supfull & \suphalf & \suphalf & \supfull & \supnone & \supnone & \supnone? & \supnone & \supnone? &?\\ 
\hline
\cite{sherman2020lambda_s} & \suphalf or \supnone? & \supnone & \supfull & \supfull & \supfull? & \supfull & \supnone? & \supnone & \supnone &?\\ 
\hline
\cite{vytiniotis2019differentiable} &
\supfull & \suphalf & \suphalf & \supfull & \supnone & \supfull & \supnone? & \supnone & \supnone? &?\\ 
\hline
\cite{mak2020differential} & \supfull & \suphalf ? & \supnone & \supfull & \supfull & \supfull & \supnone & \supnone & \supnone &?\\ 
\hline
\cite{vakar2020reverse} & \supfull & \suphalf ? & \supnone & \supfull & \supfull & \supfull & \supnone & \supnone & \supnone &?\\ 
\hline
\cite{Manzyuk2012} & \supnone & \supnone & \supnone & \supfull & \supfull? & \supfull & \supnone & \supnone & \supnone &?\\ 
\hline 
\cite{gallagher-sdg} & \supnone & \supnone & \supnone & \supfull & \supfull ? & \supfull & \supnone & \supfull & \supfull & ?  \\ 
\hline
\end{tabular}
\caption{Comparison of different differentiable programming frameworks.}
A $\supfull$ means the property is verified, and $\supnone$ means its absent from the work. Reverse stands for reverse-mode differentiation, complexity to whether there is a proof of complexity and whether its competitive, impl. stands for running implementation, pure for whether differentiation is pure or effectful, correct to whether itis proved correct, HO Fun. stands for Higher-order functions, Tensors to efficient array like structures, Rec. for term-recurion, Cond. for conditionals, and finally HO $\partial$ for higher-order derivatives.
\end{table}
%Actually very much in the spirit of Swift and Julia Zygote (see Diff.Curry intro), probably refer to this somewhere

\MH{we only have a limited form of recursion, maybe make that clearer. and we don't really have tensors, we have arrays. we don't have conditionals yet but that's something we can think of. we only have limited HO too for performance reason. maybe we should heavily emphasize we can add more but then it's harder to get guarantees and maybe not a great idea for speed...}

\MH{understand related work sentence from Diff. Curry paper: The idea of using closures as back-propagators is receiving recent attention. For example Julia Zy- gote [15] and Swift AD adopts this design. Other recent work follows similar ideas [27, 26] but is using meta-programming as an implementation technique.}

\clearpage